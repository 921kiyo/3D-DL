@inproceedings{Peng2015,
abstract = {Crowdsourced 3D CAD models are becoming easily accessible online, and can potentially generate an infinite number of training images for almost any object category.We show that augmenting the training data of contemporary Deep Convolutional Neural Net (DCNN) models with such synthetic data can be effective, especially when real training data is limited or not well matched to the target domain. Most freely available CAD models capture 3D shape but are often missing other low level cues, such as realistic object texture, pose, or background. In a detailed analysis, we use synthetic CAD-rendered images to probe the ability of DCNN to learn without these cues, with surprising findings. In particular, we show that when the DCNN is fine-tuned on the target detection task, it exhibits a large degree of invariance to missing low-level cues, but, when pretrained on generic ImageNet classification, it learns better when the low-level cues are simulated. We show that our synthetic DCNN training approach significantly outperforms previous methods on the PASCAL VOC2007 dataset when learning in the few-shot scenario and improves performance in a domain shift scenario on the Office benchmark.},
archivePrefix = {arXiv},
arxivId = {1412.7122},
author = {Peng, Xingchao and Sun, Baochen and Ali, Karim and Saenko, Kate},
booktitle = {ICCV '15 Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV)},
eprint = {1412.7122},
file = {::},
month = {dec},
title = {{Learning Deep Object Detectors from 3D Models}},
url = {http://arxiv.org/abs/1412.7122},
year = {2015}
}
@article{Su2015,
archivePrefix = {arXiv},
arxivId = {1505.05641},
author = {Su, Hao and Qi, Charles R. and Li, Yangyan and Guibas, Leonidas},
eprint = {1505.05641},
file = {::},
month = {may},
title = {{Render for CNN: Viewpoint Estimation in Images Using CNNs Trained with Rendered 3D Model Views}},
url = {http://arxiv.org/abs/1505.05641},
year = {2015}
}
@article{Arjovsky2017,
abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
archivePrefix = {arXiv},
arxivId = {1701.07875},
author = {Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'{e}}on},
eprint = {1701.07875},
file = {:D$\backslash$:/old{\_}files/aaaaa/Anglie/imperial/2017-2018/group{\_}project/1701.07875.pdf:pdf},
isbn = {1406.2661},
issn = {1701.07875},
title = {{Wasserstein GAN}},
url = {http://arxiv.org/abs/1701.07875},
year = {2017}
}
@inproceedings{Savarese2007,
abstract = {We propose a novel and robust model to represent and learn generic 3D object categories. We aim to solve the problem of true 3D object categorization for handling arbitrary rotations and scale changes. Our approach is to capture a compact model of an object category by linking together diagnostic parts of the objects from different viewing points. We emphasize on the fact that our "parts" are large and discriminative regions of the objects that are composed of many local invariant features. Instead of recovering a full 3D geometry, we connect these parts through their mutual homographic transformation. The resulting model is a compact summarization of both the appearance and geometry information of the object class. We propose a framework in which learning is done via minimal supervision compared to previous works. Our results on categorization show superior performances to state-of-the-art algorithms such as (Thomas et al., 2006). Furthermore, we have compiled a new 3D object dataset that consists of 10 different object categories. We have tested our algorithm on this dataset and have obtained highly promising results.},
author = {Savarese, Silvio and Fei-Fei, Li},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2007.4408987},
file = {:C$\backslash$:/Users/Pavel/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Savarese, Fei-Fei - 2007 - 3D generic object categorization, localization and pose estimation(2).pdf:pdf},
isbn = {978-1-4244-1630-1},
issn = {1550-5499},
title = {{3D generic object categorization, localization and pose estimation}},
year = {2007}
}
@article{Rawat2017,
abstract = {Convolutional neural networks (CNNs) have been applied to visual tasks since the late 1980s. However, despite a few scattered applications, they were dormant until the mid-2000s when developments in computing power and the advent of large amounts of labeled data, supplemented by improved algorithms, contributed to their advancement and brought them to the forefront of a neural network renaissance that has seen rapid progression since 2012. In this review, which focuses on the application of CNNs to image classification tasks, we cover their development, from their predecessors up to recent state-of-the-art deep learning systems. Along the way, we analyze (1) their early successes, (2) their role in the deep learning renaissance, (3) selected symbolic works that have con-tributed to their recent popularity, and (4) several improvement attempts by reviewing contributions and challenges of over 300 publications. We also introduce some of their current trends and remaining challenges.},
author = {Rawat, Waseem and Wang, Zenghui},
doi = {10.1162/NECO_a_00990},
file = {:C$\backslash$:/Users/Pavel/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rawat, Wang - Unknown - Deep Convolutional Neural Networks for Image Classification A Comprehensive Review.pdf:pdf},
journal = {Neural Computation},
number = {9},
pages = {2352--2449},
title = {{Deep Convolutional Neural Networks for Image Classification: A Comprehensive Review}},
url = {https://www.mitpressjournals.org/doi/pdf/10.1162/neco{\_}a{\_}00990},
volume = {29},
year = {2017}
}
@misc{Shlens2016,
author = {Shlens, Jon},
title = {{Research Blog: Train your own image classifier with Inception in TensorFlow}},
url = {https://research.googleblog.com/2016/03/train-your-own-image-classifier-with.html},
urldate = {2018-01-23},
year = {2016}
}
@misc{Google2017,
author = {Google},
title = {{How to Retrain Inception's Final Layer for New Categories  |  TensorFlow}},
url = {https://www.tensorflow.org/tutorials/image{\_}retraining},
urldate = {2018-01-23},
year = {2017}
}
