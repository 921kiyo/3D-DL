from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
from datetime import datetime
import hashlib
import os.path
import random
import re
import sys
import tarfile

import numpy as np
from six.moves import urllib
import tensorflow as tf

from tensorflow.contrib.quantize.python import quant_ops
from tensorflow.python.framework import graph_util
from tensorflow.python.framework import tensor_shape
from tensorflow.python.platform import gfile
from tensorflow.python.util import compat
from sklearn.manifold import TSNE

import matplotlib.pyplot as plt
from skimage import io
from skimage import exposure, img_as_float, img_as_ubyte
import json

def create_label_lists(label_path, json_path):
    """
    creates a label to encoding dict and a reverse dict via an output
    label txt file generated by retraining.py
    :param label_path: output label file name
    :param json_path: path to product json file
    :return: label to encoding dict and a reverse of that
    """
    with open(label_path) as f:
        labels = f.readlines()
    labels = [l.strip() for l in labels]

    label2idx = {}
    idx2label = {}
    for label_idx, label_name in enumerate(labels):
        label2idx[label_name] = label_idx
        idx2label[label_idx] = label_name

    f = open(json_path, "r")
    G = json.load(f)
    label2name = {}
    for product in G['products']:
        label2name[product['sku']] = product['name']

    return label2idx, idx2label, label2name

def get_random_test_files(filedir, label2idx, n=5, israndom=True, num_labels=None):
    """
    Iterates through the folder structure and picks a random file from
    each folder. Goes through folder structure n times
    :param filedir: directory containing the folders/files
    :param label2idx: dict containing the encoding of each label
    :param n: number of times to iterate over folder structure
    :return: list of tuples of the form (label, encoding, filepath)
    """

    test_files = [] #list of (label, filename) tuple
    count_labels = 0

    for (dirpath,dirnames,filenames) in os.walk(filedir):

        if israndom:
            filenames_r = np.random.permutation(filenames)
        else:
            filenames_r = filenames

        if num_labels is not None :
            if count_labels > num_labels :
                continue

        for i in range(n):

            num_files = len(filenames_r)

            if num_files == 0:
                continue

            filepath = os.path.join(dirpath,filenames_r[i])
            label = os.path.basename(dirpath)
            test_files.append((label, label2idx[label], filepath))

        count_labels += 1


    return test_files

def create_model_graph(model_info):
  """"Creates a graph from saved GraphDef file and returns a Graph object.

  Args:
    model_info: Dictionary containing information about the model architecture.

  Returns:
    Graph holding the trained Inception network, and the input tensor and result
    tensor as built in retraining.py
  """
  with tf.Graph().as_default() as graph:
    model_path = os.path.join(model_info['data_url'], model_info['model_file_name'])
    print('Model path: ', model_path)
    with gfile.FastGFile(model_path, 'rb') as f:
      graph_def = tf.GraphDef()
      graph_def.ParseFromString(f.read())
      resized_input_tensor, bottleneck_tensor, result_tensor = (tf.import_graph_def(
          graph_def,
          name='',
          return_elements=[
              model_info['resized_input_tensor_name'],
              model_info['bottleneck_tensor_name'],
              model_info['result_tensor_name'],
          ]))
  return graph, resized_input_tensor, bottleneck_tensor, result_tensor


def ensure_dir_exists(dir_name):
  """Makes sure the folder exists on disk.

  Args:
    dir_name: Path string to the folder we want to create.
  """
  if not os.path.exists(dir_name):
    os.makedirs(dir_name)


def create_model_info(data_url):
  """Given the name of a model architecture, returns information about it.

  Args:
    Nothing

  Returns:
    Dictionary of information about the model, or None if the name isn't
    recognized

  Raises:
    ValueError: If architecture name is unknown.
  """
  model_file_name = 'output_graph.pb'
  result_tensor_name = 'final_result:0'
  resized_input_tensor_name = 'Mul:0'
  input_width = 299
  input_height = 299
  input_depth = 3
  input_mean = 128
  input_std = 128
  bottleneck_tensor_name = 'pool_3/_reshape:0'
  bottleneck_tensor_size = 2048
  return {
      'data_url': data_url,
      'result_tensor_name': result_tensor_name,
      'resized_input_tensor_name': resized_input_tensor_name,
      'model_file_name': model_file_name,
      'bottleneck_tensor_name' : bottleneck_tensor_name,
      'bottleneck_tensor_size': bottleneck_tensor_size,
      'input_width': input_width,
      'input_height': input_height,
      'input_depth': input_depth,
      'input_mean': input_mean,
      'input_std': input_std,
  }


def run_resize_data(sess, image_data, image_data_tensor, decoded_image_tensor, decoded_jpeg):
    # Decode the JPEG image, resize it, and rescale the pixel values.
    resized_input_values, decoded_jpeg_data \
        = sess.run([decoded_image_tensor, decoded_jpeg],
                   {image_data_tensor: image_data})
    return resized_input_values, decoded_jpeg_data

def adaptive_equalize(img):
    # Adaptive Equalization
    img = img_as_float(img)
    img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.05)
    return img_as_ubyte(img_adapteq)

def tf_equalize(img_tnsr):
    IMAGE_WIDTH = 1280
    IMAGE_HEIGHT = 1024
    IMAGE_DEPTH = 3
    image_rot = tf.py_func(adaptive_equalize, [img_tnsr], tf.uint8)
    image_rot.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH])  # when using pyfunc, need to do this??
    return image_rot

def add_jpeg_decoding(input_width, input_height, input_depth, input_mean,
                      input_std):
  """Adds operations that perform JPEG decoding and resizing to the graph..

  Args:
    input_width: Desired width of the image fed into the recognizer graph.
    input_height: Desired width of the image fed into the recognizer graph.
    input_depth: Desired channels of the image fed into the recognizer graph.
    input_mean: Pixel value that should be zero in the image for the graph.
    input_std: How much to divide the pixel values by before recognition.

  Returns:
    Tensors for the node to feed JPEG data into, and the output of the
      preprocessing steps.
  """
  jpeg_data = tf.placeholder(tf.string, name='DecodeJPGInput')
  decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)
  decoded_image = tf_equalize(decoded_image)
  decoded_image_as_float = tf.cast(decoded_image, dtype=tf.float32)
  decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)
  resize_shape = tf.stack([input_height, input_width])
  resize_shape_as_int = tf.cast(resize_shape, dtype=tf.int32)
  resized_image = tf.image.resize_bilinear(decoded_image_4d,
                                           resize_shape_as_int)
  offset_image = tf.subtract(resized_image, input_mean)
  mul_image = tf.multiply(offset_image, 1.0 / input_std)
  return jpeg_data, mul_image, decoded_image


def eval_result(result_tensor, ground_truth, idx2label):
    result = np.argmax(result_tensor,axis=1)
    prediction = (ground_truth==result[0])
    correct_label = idx2label[ground_truth]
    predicted_label = idx2label[result[0]]
    return prediction, correct_label, predicted_label

def main(_):
  # Needed to make sure the logging output is visible.
  # See https://github.com/tensorflow/tensorflow/issues/3047
  tf.logging.set_verbosity(tf.logging.INFO)

  # Gather information about the model architecture we'll be using.
  model_info = create_model_info(FLAGS.model_source_dir)

  graph, resized_input_tensor, bottleneck_tensor, result_tensor = create_model_graph(model_info)

  # Look at the folder structure, and create lists of all the images.
  label2idx, idx2label, label2name = create_label_lists(
      FLAGS.label_path, FLAGS.json_path)
  test_data = get_random_test_files(FLAGS.test_file_dir, label2idx, n=FLAGS.num_test, israndom=True, num_labels=FLAGS.num_labels)

  with tf.Session(graph=graph) as sess:

    # set up jpeg decoding network
    jpeg_data_tensor, resized_image_tensor, decoded_jpeg_tensor = add_jpeg_decoding(
        model_info['input_width'], model_info['input_height'],
        model_info['input_depth'], model_info['input_mean'],
        model_info['input_std'])

    # Set up all our weights to their initial default values.
    init = tf.global_variables_initializer()
    sess.run(init)

    test_results = []
    features = []

    count = 0

    for test_datum in test_data:

        if(count%FLAGS.notify_interval == 0):
            print('processed {0}, {1} more to go'.format(count,len(test_data)-count) )

        test_result = {}

        # read in image data
        image_data = gfile.FastGFile(test_datum[2], 'rb').read()
        ground_truth = test_datum[1]

        # fetch resized image from the resizing network
        resized_image_data, decoded_jpeg_data = run_resize_data(
            sess, image_data, jpeg_data_tensor, resized_image_tensor, decoded_jpeg_tensor)


        # feed resized image into Inception network, output result
        result, bottleneck = sess.run(
            [result_tensor, bottleneck_tensor],
            feed_dict={resized_input_tensor: resized_image_data}
        )

        # decode result tensor here since we don't have access to the prediction tensor
        test_result['prediction'], test_result['correct_label'], test_result['predicted_label'] = \
            eval_result(result, ground_truth, idx2label)
        test_result['image'] = np.array(decoded_jpeg_data)
        test_result['features'] = bottleneck[0]
        test_results.append(test_result)
        #features.append(bottleneck[0])

        count += 1

    features = np.array(features)
    print('feature shape: ', features.shape)

    print('Performing dimensionality reduction with tSNE...')

    # dim reduction on the features!
    tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact')
    two_d_embeddings = tsne.fit_transform(features)

    from textwrap import wrap
    # Visualize some data
    num_correct = 0
    num_incorrect = 0
    num_viz = 4
    plt.figure()
    for result in test_results:
        predicted = result['predicted_label']
        correct = result['correct_label']
        if result['prediction']:
            num_correct += 1
            if(num_correct > num_viz):
                continue
            plt.subplot(2,num_viz,num_correct)
            plt.imshow(result['image'])
            plt.title("\n".join(wrap('Pred: {0}'.format(label2name[correct]),30)))
        if not result['prediction']:
            num_incorrect += 1
            if(num_incorrect > num_viz):
                continue
            plt.subplot(2, num_viz, num_incorrect + num_viz)
            plt.imshow(result['image'])
            plt.title("\n".join(wrap('Pred: {0}, \n Corr: {1}'.format(label2name[predicted], label2name[correct]),30)))
    print('accuracy : {}%'.format(100*num_correct/len(test_results)))
    plt.show()

    label2col = {}
    for label in label2name.keys():
        label_id = int(label)
        label2col[label] = '#' + "{0:0{1}x}".format((label_id + np.random.randint(0,0xFFFFFF)) % 0xFFFFFF,6)
        print(label + ' color is : ' + label2col[label])

    plt.figure()
    for i, result in enumerate(test_results):
        x,y = two_d_embeddings[i,:]
        plt.scatter(x,y,color=label2col[result['correct_label']], label=result['correct_label'])
    plt.title('2D visualization of features via TSNE reduction')

    import pickle

    with open(FLAGS.test_result_path, 'wb') as f:  # Python 3: open(..., 'wb')
        pickle.dump(test_results, f)



if __name__ == '__main__':
  parser = argparse.ArgumentParser()
  parser.add_argument(
      '--model_source_dir',
      type=str,
      default='./tmp/',
      help="""\
      directory containing the model graph.\
      """)

  parser.add_argument(
      '--label_path',
      type=str,
      default='./tmp/output_labels.txt',
      help="""\
          file containing the labels associated with the products.\
          """)

  parser.add_argument(
      '--json_path',
      type=str,
      default='D:/PycharmProjects/product-image-dataset-v0.1/products.json',
      help="""\
            file name of the json file containing the product information.\
            """)

  parser.add_argument(
      '--test_file_dir',
      type=str,
      default='D:/PycharmProjects/Products2',
      help="""\
              directory containing the test images.\
              """)

  parser.add_argument(
      '--test_result_path',
      type=str,
      default='./tmp/training_results.pkl',
      help="""\
              directory to store the test results.\
              """)

  parser.add_argument(
      '--num_test',
      type=int,
      default=50,
      help="""\
                number of samples per class to test.\
                """)

  parser.add_argument(
      '--num_labels',
      type=int,
      default=2,
      help="""\
                  number of classes to test.\
                  """)

  parser.add_argument(
      '--notify_interval',
      type=int,
      default=20,
      help="""\
                    number of classes to test.\
                    """)

  FLAGS, unparsed = parser.parse_known_args()

  tf.app.run(main=main)
